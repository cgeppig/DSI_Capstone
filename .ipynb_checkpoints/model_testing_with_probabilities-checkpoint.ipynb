{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bleach(string):\n",
    "    temp = \"\"\n",
    "    string = str(string)\n",
    "    for i in string:\n",
    "        if i in [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\".\"]:\n",
    "            temp += i\n",
    "    if len(temp) > 0:\n",
    "        return float(temp)\n",
    "\n",
    "def combine_list(list):\n",
    "    temp = \"\"\n",
    "    for i in list:\n",
    "        temp += \" \" + i\n",
    "    return temp\n",
    "\n",
    "def get_api_from_id(title_id):\n",
    "    this_url = \"http://www.omdbapi.com/?i=\" + title_id + \"&plot=full&r=json&apikey=9f5296af\"\n",
    "    req = requests.get(this_url)\n",
    "    return req.json()\n",
    "    sleep(2)\n",
    "\n",
    "def df_from_api(title_id):\n",
    "    df = pd.DataFrame(data=[title_id], columns=['imdb_id'])\n",
    "    df['json'] = df['imdb_id'].apply(get_api_from_id)\n",
    "    df['name'] = df['json'].apply(lambda x: x['Title'])\n",
    "    df['genres'] = df['json'].apply(lambda x: str.lower(str(x['Genre'])))\n",
    "    df['seasons'] = df['json'].apply(lambda x: bleach(x['totalSeasons']))\n",
    "    df['runtime'] = df['json'].apply(lambda x: bleach(x['Runtime']))\n",
    "    df['release_date'] = df['json'].apply(lambda x: x['Released'])\n",
    "    sleep(2)\n",
    "    return df\n",
    "\n",
    "def parse_genres(df):\n",
    "    genre_names = ['action', u'adventure', u'animation', u'biography', u'comedy',\n",
    "           u'crime', u'documentary', u'drama', u'family', u'fantasy',\n",
    "           u'game', u'history', u'horror', u'music', u'musical', u'mystery',\n",
    "           u'news', u'reality', u'romance', u'sci', u'short', u'sport', u'talk',\n",
    "           u'thriller', u'war', u'western']\n",
    "    for i in genre_names:\n",
    "        df['is_%s' % i] = df['genres'].apply(lambda x: 1 if i in x.lower() else 0)\n",
    "\n",
    "def scrape_network(id):\n",
    "    words = \"\"\n",
    "    url = \"http://www.imdb.com/title/\" + id + \"/companycredits?ref_=ttspec_sa_5\"\n",
    "    soup = BeautifulSoup(urllib2.urlopen(url), 'lxml')\n",
    "    simpleLists = soup.find_all('ul', {'class': 'simpleList'})\n",
    "    try:\n",
    "        for li in simpleLists[1]('li'):\n",
    "            for a in li('a'):\n",
    "                words += (a.get_text() + '\\n')\n",
    "        return words.split(\"\\n\")[0]\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "    sleep(2)\n",
    "\n",
    "\n",
    "def access_keyword_page(imdbID):\n",
    "    return 'http://www.imdb.com/title/' + imdbID + '/keywords?ref_=tt_stry_kw'\n",
    "\n",
    "def scrape_keywords(imdbID):\n",
    "    soup_for_keywords = BeautifulSoup(urllib2.urlopen(access_keyword_page(imdbID)), 'lxml')\n",
    "    temp_keywords = []\n",
    "    for div in soup_for_keywords('div', {'id':'keywords_content'}):\n",
    "        for text in div('div', {'class':'sodatext'}):\n",
    "            for a in text('a'):\n",
    "                temp_keywords.append(a.get_text())\n",
    "    return temp_keywords\n",
    "    sleep(2)\n",
    "\n",
    "def parse_keywords(df):\n",
    "    keywords_to_use_2 = [u'adult', u'african', u'alien',\n",
    "           u'american', u'angel', u'anim', u'base', u'best', u'black', u'book',\n",
    "           u'boy', u'boyfriend', u'brother', u'california', u'celebr', u'charact',\n",
    "           u'child', u'citi', u'comedi', u'comedian', u'comic', u'cult',\n",
    "           u'daughter', u'death', u'detect', u'doctor', u'evil', u'famili',\n",
    "           u'father', u'femal', u'fiction',u'friend', u'friendship',\n",
    "           u'gay', u'girl', u'girlfriend', u'hero', u'humor',\n",
    "           u'husband', u'interraci', u'interview', u'investig', u'joke',\n",
    "           u'life', u'live', u'love', u'male', u'man', u'marriag', u'mother',\n",
    "           u'murder',u'offic', u'parent', u'parodi',\n",
    "           u'play', u'polic', u'power', u'protagonist', u'relationship', u'satir',\n",
    "           u'school', u'secret',u'sex', u'share', u'sister', u'sitcom',\n",
    "           u'social', u'son', u'spoken', u'spoof', u'stand', u'student',\n",
    "           u'superhero', u'supernatur', u'surreal', u'teenag',\n",
    "           u'versu', u'villain', u'violenc', u'wife', u'woman',\n",
    "           u'york']\n",
    "    for i in keywords_to_use_2:\n",
    "        df['keyword_%s' % i] = df['keywords'].apply(lambda x: 1 if i in x else 0)\n",
    "\n",
    "def parse_dates(df):\n",
    "    df['release_date'] = df['release_date'].apply(lambda x: datetime.strptime(x, '%d %b %Y'))\n",
    "    df['release_month'] = df['release_date'].apply(lambda x: x.strftime('%m'))\n",
    "    df['release_weekday'] = df['release_date'].apply(lambda x: x.strftime('%w'))\n",
    "    df['release_monthday'] = df['release_date'].apply(lambda x: x.strftime('%d'))\n",
    "    df['started_sunday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==0 else 0)\n",
    "    df['started_monday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==1 else 0)\n",
    "    df['started_tuesday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==2 else 0)\n",
    "    df['started_wednesday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==3 else 0)\n",
    "    df['started_thursday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==4 else 0)\n",
    "    df['started_friday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==5 else 0)\n",
    "    df['started_saturday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==6 else 0)\n",
    "    df['started_january'] = df['release_month'].apply(lambda x: 1 if int(x)==1 else 0)\n",
    "    df['started_february'] = df['release_month'].apply(lambda x: 1 if int(x)==2 else 0)\n",
    "    df['started_march'] = df['release_month'].apply(lambda x: 1 if int(x)==3 else 0)\n",
    "    df['started_april'] = df['release_month'].apply(lambda x: 1 if int(x)==4 else 0)\n",
    "    df['started_may'] = df['release_month'].apply(lambda x: 1 if int(x)==5 else 0)\n",
    "    df['started_june'] = df['release_month'].apply(lambda x: 1 if int(x)==6 else 0)\n",
    "    df['started_july'] = df['release_month'].apply(lambda x: 1 if int(x)==7 else 0)\n",
    "    df['started_august'] = df['release_month'].apply(lambda x: 1 if int(x)==8 else 0)\n",
    "    df['started_september'] = df['release_month'].apply(lambda x: 1 if int(x)==9 else 0)\n",
    "    df['started_october'] = df['release_month'].apply(lambda x: 1 if int(x)==10 else 0)\n",
    "    df['started_november'] = df['release_month'].apply(lambda x: 1 if int(x)==11 else 0)\n",
    "    df['started_december'] = df['release_month'].apply(lambda x: 1 if int(x)==12 else 0)\n",
    "    df['first_year'] = df['release_date'].apply(lambda x: int(x.strftime('%Y')))\n",
    "    df['started_on_first'] = df['release_monthday'].dropna().apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "def parse_runtime(df):\n",
    "    df['runtime'].fillna(value=0, inplace=True)\n",
    "    df['half_hour'] = df['runtime'].apply(lambda x: 1 if (int(x)<= 30) and (int(x)>= 20) else 0)\n",
    "    df['full_hour'] = df['runtime'].apply(lambda x: 1 if (int(x)<= 60) and (int(x)>= 40) else 0)\n",
    "\n",
    "def parse_network(df):\n",
    "    networks = ['ABC', 'NBC', 'CBS', 'Fox', 'Nickelodeon', 'Cartoon', 'Comedy', 'MTV',\n",
    "               'HBO', 'Disney', 'WB']\n",
    "    for i in networks:\n",
    "        df['from_' + i] = df['network'].apply(lambda x: 1 if i in x else 0)\n",
    "\n",
    "def define_features(df):\n",
    "    df2 = df\n",
    "    df2.drop(['name', 'runtime', 'imdb_id', 'json', 'genres', 'seasons', 'release_date', 'network', \n",
    "              'keywords', 'release_month', 'release_weekday'], inplace=True, axis=1)\n",
    "    return df2\n",
    "\n",
    "\n",
    "## make a different function that opens the pickled model and runs the df through it\n",
    "\n",
    "def get_tv_prediction(imdb_id):\n",
    "    df1 = df_from_api(imdb_id)\n",
    "    print \"queried the api\"\n",
    "    df1['keywords'] = df1['imdb_id'].apply(lambda x: combine_list(scrape_keywords(x)))\n",
    "    df1['network'] = df1['imdb_id'].apply(lambda x: (str(scrape_network(x))))\n",
    "    print \"scraped all data\"\n",
    "    parse_keywords(df1)\n",
    "    parse_network(df1)\n",
    "    parse_dates(df1)\n",
    "    parse_genres(df1)\n",
    "    parse_runtime(df1)\n",
    "    print \"parsed all data\"\n",
    "    name = df1['name'].values[0]\n",
    "    print \"this show is: \", name\n",
    "    df2 = define_features(df1)\n",
    "    print \"defined features\"\n",
    "    model_pickle_path = 'model_implementation/gsrf_pickle.pkl'\n",
    "    model_unpickle = open(model_pickle_path, 'rb')\n",
    "    gsrf= pickle.load(model_unpickle)\n",
    "    print \"loaded model\"\n",
    "    prediction = gsrf.predict(df2)\n",
    "    print prediction\n",
    "    predict_proba = str(gsrf.predict_proba(df2)[0][0]*100)[:5]\n",
    "#     prediction = [\"CANCELLED\" if ada_boost.predict(df2) == 1 else \"RENEWED\"] ## add [0] to remove brackets\n",
    "    print \"prediction is: \", prediction\n",
    "    # print \"The model predicts that %s will be %s\" %(name, prediction[0])\n",
    "    print \"model ran\"\n",
    "    print \"returned predictions\"\n",
    "    print \"The model predicts a %s percent chance of %s being renewed\" %(predict_proba, name)\n",
    "    return [name, predict_proba]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queried the api\n",
      "scraped all data\n",
      "parsed all data\n",
      "this show is:  The Simpsons\n",
      "defined features\n",
      "loaded model\n",
      "prediction is:  [0]\n",
      "model ran\n",
      "returned predictions\n",
      "The model predicts a 50.86 percent chance of The Simpsons being renewed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'The Simpsons', '50.86']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tv_prediction('tt0096697')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sherlock = 'tt1475582'   ## 66.49%\n",
    "game_of_thrones = 'tt0944947'   ## 52.79%\n",
    "invasion = \"tt0460651\"  ## 55.1%\n",
    "grimm = 'tt1830617'     # 66.4%\n",
    "firefly = 'tt0303461'   ## 50.18%\n",
    "futurama = 'tt0149460'  ## 55.93%\n",
    "powerless = 'tt5083928' ## 53.47%\n",
    "glow = 'tt5770786'      ## can't figure it out--no release date\n",
    "the_young_pope = 'tt3655448'  # 48.03%\n",
    "the_good_place = \"tt4955642\"  ## 51.5%\n",
    "american_gods = 'tt1898069'   ## 63.66%\n",
    "claws = 'tt5640558'   ## 53.42%\n",
    "dear_white_people = 'tt5707802'   ## 52.63%\n",
    "downward_dog = 'tt3879306'   ## 51.96%\n",
    "handmaidens_tale = 'tt5834204'  ## 59.91%\n",
    "the_simpsons = 'tt0096697' ## 50.86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queried the api\n",
      "scraped all data\n",
      "parsed all data\n",
      "this show is:  Killer Women\n",
      "defined features\n",
      "loaded model\n",
      "prediction is:  [1]\n",
      "model ran\n",
      "returned predictions\n",
      "The model predicts a 46.35 percent chance of Killer Women being renewed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'Killer Women', '46.35']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## killer women\n",
    "get_tv_prediction('tt2657258')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model predicts a 66.0 percent chance of being renewed\n"
     ]
    }
   ],
   "source": [
    "thing_one = 0.66\n",
    "print \"the model predicts a %s percent chance of being renewed\" % (thing_one*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thing1 = 234*3546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829%\n"
     ]
    }
   ],
   "source": [
    "print str(thing1)[:3] + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
