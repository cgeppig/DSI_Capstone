{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option('max_seq_items', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleach(string):\n",
    "    temp = \"\"\n",
    "    string = str(string)\n",
    "    for i in string:\n",
    "        if i in [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\".\"]:\n",
    "            temp += i\n",
    "    if len(temp) > 0:\n",
    "        return float(temp)\n",
    "\n",
    "def combine_list(list):\n",
    "    temp = \"\"\n",
    "    for i in list:\n",
    "        temp += \" \" + i\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get API info from IMDBid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## gets complete information from omdbapi using the imdb id\n",
    "\n",
    "def get_api_from_id(title_id):\n",
    "    this_url = \"http://www.omdbapi.com/?i=\" + title_id + \"&plot=full&r=json&apikey=9f5296af\"\n",
    "    req = requests.get(this_url)\n",
    "    return req.json()\n",
    "#     print req.json()\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_from_api(title_id):\n",
    "    df = pd.DataFrame(data=[title_id], columns=['imdb_id'])\n",
    "    ## check the column names here against the column names in the dataset\n",
    "    df['json'] = df['imdb_id'].apply(get_api_from_id)\n",
    "    df['name'] = df['json'].apply(lambda x: x['Title'])\n",
    "    df['genres'] = df['json'].apply(lambda x: str.lower(str(x['Genre'])))\n",
    "    df['seasons'] = df['json'].apply(lambda x: bleach(x['totalSeasons']))\n",
    "    df['runtime'] = df['json'].apply(lambda x: bleach(x['Runtime']))\n",
    "    df['release_date'] = df['json'].apply(lambda x: x['Released'])\n",
    "    sleep(2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_genres(df):\n",
    "    # create dummy variables of all of the genres\n",
    "    genre_names = ['action', u'adventure', u'animation', u'biography', u'comedy',\n",
    "           u'crime', u'documentary', u'drama', u'family', u'fantasy',\n",
    "           u'game', u'history', u'horror', u'music', u'musical', u'mystery',\n",
    "           u'news', u'reality', u'romance', u'sci', u'short', u'sport', u'talk',\n",
    "           u'thriller', u'war', u'western']\n",
    "\n",
    "    for i in genre_names:\n",
    "        df['is_%s' % i] = df['genres'].apply(lambda x: 1 if i in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_network(id):\n",
    "    words = \"\"\n",
    "    url = \"http://www.imdb.com/title/\" + id + \"/companycredits?ref_=ttspec_sa_5\"\n",
    "    soup = BeautifulSoup(urllib2.urlopen(url))\n",
    "    simpleLists = soup.find_all('ul', {'class': 'simpleList'})\n",
    "    try:\n",
    "        for li in simpleLists[1]('li'):\n",
    "            for a in li('a'):\n",
    "                words += (a.get_text() + '\\n')\n",
    "        return words.split(\"\\n\")[0]\n",
    "#         print words.split(\"\\n\")[0]\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Accesses page based on imdb id\n",
    "\n",
    "def access_keyword_page(imdbID):\n",
    "    ## imdbID needs to be added in str format\n",
    "    return 'http://www.imdb.com/title/' + imdbID + '/keywords?ref_=tt_stry_kw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_keywords(imdbID):\n",
    "    soup_for_keywords = BeautifulSoup(urllib2.urlopen(access_keyword_page(imdbID)))\n",
    "    temp_keywords = []\n",
    "    for div in soup_for_keywords('div', {'id':'keywords_content'}):\n",
    "        for text in div('div', {'class':'sodatext'}):\n",
    "            for a in text('a'):\n",
    "    #             print a.get_text()\n",
    "                temp_keywords.append(a.get_text())\n",
    "    return temp_keywords\n",
    "#     print temp_keywords\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_keywords(df):\n",
    "    # for making keyword dummy variables\n",
    "    keywords_to_use_2 = [u'adult', u'african', u'alien',\n",
    "           u'american', u'angel', u'anim', u'base', u'best', u'black', u'book',\n",
    "           u'boy', u'boyfriend', u'brother', u'california', u'celebr', u'charact',\n",
    "           u'child', u'citi', u'comedi', u'comedian', u'comic', u'cult',\n",
    "           u'daughter', u'death', u'detect', u'doctor', u'evil', u'famili',\n",
    "           u'father', u'femal', u'fiction',u'friend', u'friendship',\n",
    "           u'gay', u'girl', u'girlfriend', u'hero', u'humor',\n",
    "           u'husband', u'interraci', u'interview', u'investig', u'joke',\n",
    "           u'life', u'live', u'love', u'male', u'man', u'marriag', u'mother',\n",
    "           u'murder',u'offic', u'parent', u'parodi',\n",
    "           u'play', u'polic', u'power', u'protagonist', u'relationship', u'satir',\n",
    "           u'school', u'secret',u'sex', u'share', u'sister', u'sitcom',\n",
    "           u'social', u'son', u'spoken', u'spoof', u'stand', u'student',\n",
    "           u'superhero', u'supernatur', u'surreal', u'teenag',\n",
    "           u'versu', u'villain', u'violenc', u'wife', u'woman',\n",
    "           u'york']\n",
    "\n",
    "    for i in keywords_to_use_2:\n",
    "        df['keyword_%s' % i] = df['keywords'].apply(lambda x: 1 if i in x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_dates(df):\n",
    "    df['release_date'] = df['release_date'].apply(lambda x: datetime.strptime(x, '%d %b %Y'))\n",
    "    df['release_month'] = df['release_date'].apply(lambda x: x.strftime('%m'))\n",
    "    df['release_weekday'] = df['release_date'].apply(lambda x: x.strftime('%w'))\n",
    "    ## day of the month\n",
    "    df['release_monthday'] = df['release_date'].apply(lambda x: x.strftime('%d'))\n",
    "    ## days of the week\n",
    "    df['started_sunday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==0 else 0)\n",
    "    df['started_monday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==1 else 0)\n",
    "    df['started_tuesday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==2 else 0)\n",
    "    df['started_wednesday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==3 else 0)\n",
    "    df['started_thursday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==4 else 0)\n",
    "    df['started_friday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==5 else 0)\n",
    "    df['started_saturday'] = df['release_weekday'].apply(lambda x: 1 if int(x)==6 else 0)\n",
    "    ## months\n",
    "    df['started_january'] = df['release_month'].apply(lambda x: 1 if int(x)==1 else 0)\n",
    "    df['started_february'] = df['release_month'].apply(lambda x: 1 if int(x)==2 else 0)\n",
    "    df['started_march'] = df['release_month'].apply(lambda x: 1 if int(x)==3 else 0)\n",
    "    df['started_april'] = df['release_month'].apply(lambda x: 1 if int(x)==4 else 0)\n",
    "    df['started_may'] = df['release_month'].apply(lambda x: 1 if int(x)==5 else 0)\n",
    "    df['started_june'] = df['release_month'].apply(lambda x: 1 if int(x)==6 else 0)\n",
    "    df['started_july'] = df['release_month'].apply(lambda x: 1 if int(x)==7 else 0)\n",
    "    df['started_august'] = df['release_month'].apply(lambda x: 1 if int(x)==8 else 0)\n",
    "    df['started_september'] = df['release_month'].apply(lambda x: 1 if int(x)==9 else 0)\n",
    "    df['started_october'] = df['release_month'].apply(lambda x: 1 if int(x)==10 else 0)\n",
    "    df['started_november'] = df['release_month'].apply(lambda x: 1 if int(x)==11 else 0)\n",
    "    df['started_december'] = df['release_month'].apply(lambda x: 1 if int(x)==12 else 0)\n",
    "    ## year\n",
    "    df['first_year'] = df['release_date'].apply(lambda x: int(x.strftime('%Y')))\n",
    "    df['started_on_first'] = df['release_monthday'].dropna().apply(lambda x: 1 if x==1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_runtime(df):\n",
    "    df['half_hour'] = df['runtime'].apply(lambda x: 1 if (int(x)<= 30) and (int(x)>= 20) else 0)\n",
    "    df['full_hour'] = df['runtime'].apply(lambda x: 1 if (int(x)<= 60) and (int(x)>= 40) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_network(df):\n",
    "    networks = ['ABC', 'NBC', 'CBS', 'Fox', 'Nickelodeon', 'Cartoon', 'Comedy', 'MTV',\n",
    "               'HBO', 'Disney', 'WB']\n",
    "    for i in networks:\n",
    "        df['from_' + i] = df['network'].apply(lambda x: 1 if i in x else 0)\n",
    "    \n",
    "# 'from_ABC', u'from_NBC', u'from_CBS', u'from_Fox', u'from_Nickelodeon',\n",
    "#        u'from_Cartoon', u'from_Comedy', u'from_MTV', u'from_HBO',\n",
    "#        u'from_Disney', u'from_WB'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## delete errant columns\n",
    "## drop: name, runtime, imdb_id, json, genres, seasons, release_date, network, keywords, \n",
    "## keep original dataframe so the script can output the show title, and retrieve other information\n",
    "    ## like number of seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_features(df):\n",
    "    df2 = df\n",
    "    df2.drop(['name', 'runtime', 'imdb_id', 'json', 'genres', 'seasons', 'release_date', 'network', \n",
    "              'keywords', 'release_month', 'release_weekday'], inplace=True, axis=1)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickled model\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_pickle_path = 'ada_boost_pickle.pkl'\n",
    "# model_unpickle = open(model_pickle_path, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make a different function that opens the pickled model and runs the df through it\n",
    "\n",
    "def get_tv_prediction(imdb_id):\n",
    "    df1 = df_from_api(imdb_id)\n",
    "    df1['keywords'] = df1['imdb_id'].apply(lambda x: combine_list(scrape_keywords(x)))\n",
    "    df1['network'] = df1['imdb_id'].apply(lambda x: (str(scrape_network(x))))\n",
    "    parse_keywords(df1)\n",
    "    parse_network(df1)\n",
    "    parse_dates(df1)\n",
    "    parse_genres(df1)\n",
    "    parse_runtime(df1)\n",
    "    name = df1['name'].values[0]\n",
    "    df2 = define_features(df1)\n",
    "#     model_pickle_path = 'ada_boost_pickle.pkl'\n",
    "#     model_unpickle = open(model_pickle_path, 'rb')\n",
    "#     ada_boost = pickle.load(model_unpickle)\n",
    "#     prediction = [\"Cancelled\" if ada_boost.predict(df2) == 1 else \"Renewed\"]\n",
    "#     print \"The model predicts that %s will be %s\" %(df1['name'].values, prediction[0])\n",
    "#     print df1\n",
    "    return name\n",
    "#     print df2\n",
    "#     return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Firefly'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tv_prediction('tt0303461')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = get_tv_prediction('tt0303461')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 143)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'keyword_offic'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns.sort_values()[91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.columns.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shows = pd.read_csv('../good_shows_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('max_seq_items', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows.columns.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
