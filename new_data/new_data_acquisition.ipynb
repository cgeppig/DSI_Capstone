{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "from imdbpie import Imdb\n",
    "from time import sleep\n",
    "import time\n",
    "import requests\n",
    "import string\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_df(list_of_shows, year):\n",
    "    temp_df = pd.DataFrame(list_of_shows, columns=['id', 'title'])\n",
    "    df_name = \"shows_\" + str(year) + '.csv'\n",
    "    temp_df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scrapes shows between 2000 and 2015\n",
    "## maybe do it by year\n",
    "## this doesn't work for some reason\n",
    "\n",
    "# all_shows = []\n",
    "# for page in range(1,111):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2000,2015&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     print \"scraping page :\"\n",
    "#     print page,\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 all_shows.append([imdbid,name])\n",
    "#                 sleep(1)\n",
    "#     sleep(1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2015 shows\n",
    "\n",
    "# shows2015 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2015,2015&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2015.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2015, 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2014 shows\n",
    "\n",
    "# shows2014 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2014,2014&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2014.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(5)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2014, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2013 shows\n",
    "\n",
    "# shows2013 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2013,2013&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2013.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2013, 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2012 shows\n",
    "# years = '2012,2012'\n",
    "# shows2012 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2013.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2012, 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2011 shows\n",
    "# year = '2011'\n",
    "# years = year + ',' + year\n",
    "# shows2011 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2013.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2011, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(shows2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## scrape all years\n",
    "\n",
    "## I made a better way of doing this\n",
    "\n",
    "# for i in range(1995,2017):\n",
    "#     year = str(i)\n",
    "#     years = year + ',' + year\n",
    "#     shows_temp = []\n",
    "#     print \"Scraping year: \", year\n",
    "#     print \"Scraped Page: \"\n",
    "#     for page in range(1,11):\n",
    "#         url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#         soup2000 = BeautifulSoup(url2000)\n",
    "#         for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#             for span in table('span', {'class': 'lister-item-header'}):\n",
    "#                 for title in span('a'):\n",
    "#                     imdbid = str(title).split('/')[2]\n",
    "#                     name = str(title).split('>')[1].split('<')[0]\n",
    "#                     shows_temp.append([imdbid, name])\n",
    "#                     sleep(2)\n",
    "#         sleep(5)\n",
    "#         print page,\n",
    "#     temp_df = pd.DataFrame(shows_temp, columns=['id', 'title'])\n",
    "#     df_name = \"shows_\" + year + '.csv'\n",
    "#     temp_df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function for scraping a single year\n",
    "## scrapes 2500 shows for the given year\n",
    "## exports as dataframe with name 'shows_[year].csv'\n",
    "\n",
    "def scrape_year(year):\n",
    "    year = str(year)\n",
    "    years = year + ',' + year\n",
    "    shows_temp = []\n",
    "    print \"Scraping Year: \", year\n",
    "    print \"Scraped Pages: \"\n",
    "    for page in range(1,11):\n",
    "        url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "        soup2000 = BeautifulSoup(url2000)\n",
    "        for table in soup2000('div', {'class': 'lister-list'}):\n",
    "            for span in table('span', {'class': 'lister-item-header'}):\n",
    "                for title in span('a'):\n",
    "                    imdbid = str(title).split('/')[2]\n",
    "                    name = str(title).split('>')[1].split('<')[0]\n",
    "                    shows_temp.append([imdbid, name])\n",
    "        print page,\n",
    "        sleep(5)\n",
    "    temp_df = pd.DataFrame(shows_temp, columns=['id', 'title'])\n",
    "    print \"\\n\", temp_df.shape[0], \" Shows Scraped\"\n",
    "    df_name = \"shows_\" + year + '.csv'\n",
    "    temp_df.to_csv(df_name, index=False)\n",
    "    print \"csv file created for: \", year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I don't know for sure whether the earlier years have 2500 shows each (it looks like they don't)\n",
    "\n",
    "\n",
    "for i in range(1995,2000):\n",
    "    scrape_year(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000,2018):\n",
    "    scrape_year(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## combining years into one dataframe\n",
    "\n",
    "for i in [\n",
    "'shows_1995.csv',             'shows_2007.csv',\n",
    "'shows_1996.csv',             'shows_2008.csv',\n",
    "'shows_1997.csv',             'shows_2009.csv',\n",
    "'shows_1998.csv',             'shows_2010.csv',\n",
    "'shows_1999.csv',             'shows_2011.csv',\n",
    "'shows_2000.csv',             'shows_2012.csv',\n",
    "'shows_2001.csv',             'shows_2013.csv',\n",
    "'shows_2002.csv',             'shows_2014.csv',\n",
    "'shows_2003.csv',             'shows_2015.csv',\n",
    "'shows_2004.csv',             'shows_2016.csv'\n",
    "'shows_2005.csv',             'shows_2017.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    all_shows = pd.concat([all_shows, df])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_shows.to_csv('all_shows.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleach(string):\n",
    "    temp = \"\"\n",
    "    string = str(string)\n",
    "    for i in string:\n",
    "        if i in [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\".\"]:\n",
    "            temp += i\n",
    "    if len(temp) > 0:\n",
    "        return float(temp)\n",
    "\n",
    "def combine_list(list):\n",
    "    temp = \"\"\n",
    "    for i in list:\n",
    "        temp += \" \" + i\n",
    "    return temp\n",
    "\n",
    "def get_api_from_id(title_id):\n",
    "    try: \n",
    "        this_url = \"http://www.omdbapi.com/?i=\" + title_id + \"&plot=full&r=json&apikey=9f5296af\"\n",
    "        req = requests.get(this_url)\n",
    "        return req.json()\n",
    "    except:\n",
    "        return \"something is wrong\"\n",
    "\n",
    "def data_from_api(df):\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['name'] = df['json'].apply(lambda x: x['Title'])\n",
    "    df['genres'] = df['json'].apply(lambda x: str.lower(str(x['Genre'])))\n",
    "    df['seasons'] = df['json'].apply(lambda x: bleach(x['totalSeasons']))\n",
    "    df['runtime'] = df['json'].apply(lambda x: bleach(x['Runtime']))\n",
    "    df['release_date'] = df['json'].apply(lambda x: x['Released'])\n",
    "\n",
    "def parse_json(df):\n",
    "    df['json_title'] = df['json'].apply(lambda x: x['Title'])\n",
    "    df['genres'] = df['json'].apply(lambda x: str.lower(str(x['Genre'])))\n",
    "    df['seasons'] = df['json'].apply(lambda x: bleach(x['totalSeasons']))\n",
    "    df['runtime'] = df['json'].apply(lambda x: bleach(x['Runtime']))\n",
    "    df['release_date'] = df['json'].apply(lambda x: x['Released'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## getting api data for the whole dataframe is a little bit rough. trying to do it individually. \n",
    "\n",
    "for i in [\n",
    "'shows_1995.csv',             'shows_2007.csv',\n",
    "'shows_1996.csv',             'shows_2008.csv',\n",
    "'shows_1997.csv',             'shows_2009.csv',\n",
    "'shows_1998.csv',             'shows_2010.csv',\n",
    "'shows_1999.csv',             'shows_2011.csv',\n",
    "'shows_2000.csv',             'shows_2012.csv',\n",
    "'shows_2001.csv',             'shows_2013.csv',\n",
    "'shows_2002.csv',             'shows_2014.csv',\n",
    "'shows_2003.csv',             'shows_2015.csv',\n",
    "'shows_2004.csv',             'shows_2016.csv'\n",
    "'shows_2005.csv',             'shows_2017.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    print \"starting with df: \", i\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df.to_csv(i, index=False)\n",
    "    print 'finished with df: ', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shows_1995.csv',\n",
       " 'shows_1996.csv',\n",
       " 'shows_1997.csv',\n",
       " 'shows_1998.csv',\n",
       " 'shows_1999.csv',\n",
       " 'shows_2000.csv',\n",
       " 'shows_2001.csv',\n",
       " 'shows_2002.csv',\n",
       " 'shows_2003.csv',\n",
       " 'shows_2004.csv',\n",
       " 'shows_2005.csv',\n",
       " 'shows_2006.csv',\n",
       " 'shows_2007.csv',\n",
       " 'shows_2008.csv',\n",
       " 'shows_2009.csv',\n",
       " 'shows_2010.csv',\n",
       " 'shows_2011.csv',\n",
       " 'shows_2012.csv',\n",
       " 'shows_2013.csv',\n",
       " 'shows_2014.csv',\n",
       " 'shows_2015.csv',\n",
       " 'shows_2016.csv',\n",
       " 'shows_2017.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x[2:]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shows_1995 = pd.read_csv('shows_1995.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows_1995.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shows_1995.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows_1995['json'] = shows_1995['id'].apply(get_api_from_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shows_1995['json'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows_1995.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_genre(json):\n",
    "    try:\n",
    "        return str.lower(str(json['Genre']))\n",
    "    except:\n",
    "        return \"there_is_a_problem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shows_1995['genre'] = shows_1995['json'].apply(parse_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shows_1995.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows_1995['genre'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how many rows made it into each dataframe?\n",
    "for i in range(1995,2018):\n",
    "    print \"Year = \", i\n",
    "    df_name = 'shows_' + str(i) + '.csv'\n",
    "    temp_df = pd.read_csv(df_name)\n",
    "    print temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shows = pd.read_csv('all_shows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26546, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0491758</td>\n",
       "      <td>Dallas Cowboys Cheerleaders: Making the Team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0775374</td>\n",
       "      <td>Lincoln Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0995011</td>\n",
       "      <td>The Electric Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0762067</td>\n",
       "      <td>Wow! Wow! Wubbzy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0498633</td>\n",
       "      <td>Secrets of a Small Town</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                         title\n",
       "0  tt0491758  Dallas Cowboys Cheerleaders: Making the Team\n",
       "1  tt0775374                               Lincoln Heights\n",
       "2  tt0995011                          The Electric Company\n",
       "3  tt0762067                             Wow! Wow! Wubbzy!\n",
       "4  tt0498633                       Secrets of a Small Town"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows['json'] = shows['id'].apply(get_api_from_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
