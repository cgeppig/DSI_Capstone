{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "from imdbpie import Imdb\n",
    "from time import sleep\n",
    "import time\n",
    "import requests\n",
    "import string\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_df(list_of_shows, year):\n",
    "    temp_df = pd.DataFrame(list_of_shows, columns=['id', 'title'])\n",
    "    df_name = \"shows_\" + str(year) + '.csv'\n",
    "    temp_df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scrapes shows between 2000 and 2015\n",
    "## maybe do it by year\n",
    "## this doesn't work for some reason\n",
    "\n",
    "# all_shows = []\n",
    "# for page in range(1,111):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2000,2015&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     print \"scraping page :\"\n",
    "#     print page,\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 all_shows.append([imdbid,name])\n",
    "#                 sleep(1)\n",
    "#     sleep(1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2015 shows\n",
    "\n",
    "# shows2015 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2015,2015&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2015.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2015, 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2014 shows\n",
    "\n",
    "# shows2014 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2014,2014&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2014.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(5)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2014, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2013 shows\n",
    "\n",
    "# shows2013 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2013,2013&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2013.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2013, 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2012 shows\n",
    "# years = '2012,2012'\n",
    "# shows2012 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2013.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2012, 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2011 shows\n",
    "# year = '2011'\n",
    "# years = year + ',' + year\n",
    "# shows2011 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2013.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2011, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(shows2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## scrape all years\n",
    "\n",
    "## I made a better way of doing this\n",
    "\n",
    "# for i in range(1995,2017):\n",
    "#     year = str(i)\n",
    "#     years = year + ',' + year\n",
    "#     shows_temp = []\n",
    "#     print \"Scraping year: \", year\n",
    "#     print \"Scraped Page: \"\n",
    "#     for page in range(1,11):\n",
    "#         url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#         soup2000 = BeautifulSoup(url2000)\n",
    "#         for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#             for span in table('span', {'class': 'lister-item-header'}):\n",
    "#                 for title in span('a'):\n",
    "#                     imdbid = str(title).split('/')[2]\n",
    "#                     name = str(title).split('>')[1].split('<')[0]\n",
    "#                     shows_temp.append([imdbid, name])\n",
    "#                     sleep(2)\n",
    "#         sleep(5)\n",
    "#         print page,\n",
    "#     temp_df = pd.DataFrame(shows_temp, columns=['id', 'title'])\n",
    "#     df_name = \"shows_\" + year + '.csv'\n",
    "#     temp_df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function for scraping a single year\n",
    "## scrapes 2500 shows for the given year\n",
    "## exports as dataframe with name 'shows_[year].csv'\n",
    "\n",
    "def scrape_year(year):\n",
    "    year = str(year)\n",
    "    years = year + ',' + year\n",
    "    shows_temp = []\n",
    "    print \"Scraping Year: \", year\n",
    "    print \"Scraped Pages: \"\n",
    "    for page in range(1,11):\n",
    "        url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "        soup2000 = BeautifulSoup(url2000)\n",
    "        for table in soup2000('div', {'class': 'lister-list'}):\n",
    "            for span in table('span', {'class': 'lister-item-header'}):\n",
    "                for title in span('a'):\n",
    "                    imdbid = str(title).split('/')[2]\n",
    "                    name = str(title).split('>')[1].split('<')[0]\n",
    "                    shows_temp.append([imdbid, name])\n",
    "        print page,\n",
    "        sleep(5)\n",
    "    temp_df = pd.DataFrame(shows_temp, columns=['id', 'title'])\n",
    "    print \"\\n\", temp_df.shape[0], \" Shows Scraped\"\n",
    "    df_name = \"shows_\" + year + '.csv'\n",
    "    temp_df.to_csv(df_name, index=False)\n",
    "    print \"csv file created for: \", year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I don't know for sure whether the earlier years have 2500 shows each (it looks like they don't)\n",
    "\n",
    "\n",
    "for i in range(1995,2000):\n",
    "    scrape_year(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000,2018):\n",
    "    scrape_year(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_shows.to_csv('all_shows.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleach(string):\n",
    "    temp = \"\"\n",
    "    string = str(string)\n",
    "    for i in string:\n",
    "        if i in [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\".\"]:\n",
    "            temp += i\n",
    "    if len(temp) > 0:\n",
    "        return float(temp)\n",
    "\n",
    "def combine_list(list):\n",
    "    temp = \"\"\n",
    "    for i in list:\n",
    "        temp += \" \" + i\n",
    "    return temp\n",
    "\n",
    "def get_api_from_id(title_id):\n",
    "    try: \n",
    "        this_url = \"http://www.omdbapi.com/?i=\" + title_id + \"&plot=full&r=json&apikey=9f5296af\"\n",
    "        req = requests.get(this_url)\n",
    "        return req.json()\n",
    "    except:\n",
    "        return \"something is wrong\"\n",
    "\n",
    "def data_from_api(df):\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['name'] = df['json'].apply(lambda x: x['Title'])\n",
    "    df['genres'] = df['json'].apply(lambda x: str.lower(str(x['Genre'])))\n",
    "    df['seasons'] = df['json'].apply(lambda x: bleach(x['totalSeasons']))\n",
    "    df['runtime'] = df['json'].apply(lambda x: bleach(x['Runtime']))\n",
    "    df['release_date'] = df['json'].apply(lambda x: x['Released'])\n",
    "\n",
    "def parse_json(df):\n",
    "    df['json_title'] = df['json'].apply(lambda x: x['Title'])\n",
    "    df['genres'] = df['json'].apply(lambda x: str.lower(str(x['Genre'])))\n",
    "    df['seasons'] = df['json'].apply(lambda x: bleach(x['totalSeasons']))\n",
    "    df['runtime'] = df['json'].apply(lambda x: bleach(x['Runtime']))\n",
    "    df['release_date'] = df['json'].apply(lambda x: x['Released'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_genre(json):\n",
    "    try:\n",
    "        return str.lower(str(json['Genre']))\n",
    "    except:\n",
    "        return \"n/a\"\n",
    "\n",
    "def parse_date(json):\n",
    "    try:\n",
    "        return str(json['Released'])\n",
    "    except:\n",
    "        return \"n/a\"\n",
    "    \n",
    "def parse_runtime(json):\n",
    "    try:\n",
    "        return int(bleach(str(json['Runtime'])))\n",
    "    except:\n",
    "        return \"n/a\"\n",
    "\n",
    "def parse_seasons(json):\n",
    "    try:\n",
    "        return int(json['totalSeasons'])\n",
    "    except:\n",
    "        return \"n/a\"\n",
    "    \n",
    "def parse_plot(json):\n",
    "    try:\n",
    "        return json['Plot']\n",
    "    except:\n",
    "        return \"n/a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_json(json):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with df:  shows_1995.csv\n",
      "finished with df:  shows_1995.csv\n"
     ]
    }
   ],
   "source": [
    "## testing\n",
    "## it seems to work well\n",
    "\n",
    "for i in [\n",
    "'shows_1995.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    print \"starting with df: \", i\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['genre'] = df['json'].apply(parse_genre)\n",
    "    df['release_date'] = df['json'].apply(parse_date)\n",
    "    df['runtime'] = df['json'].apply(parse_runtime)\n",
    "    df['seasons'] = df['json'].apply(parse_seasons)\n",
    "    df.to_csv(i, index=False)\n",
    "    print 'finished with df: ', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with df:  shows_1995.csv\n",
      "finished with df:  shows_1995.csv\n",
      "starting with df:  shows_2007.csv\n",
      "finished with df:  shows_2007.csv\n",
      "starting with df:  shows_1996.csv\n",
      "finished with df:  shows_1996.csv\n",
      "starting with df:  shows_2008.csv\n",
      "finished with df:  shows_2008.csv\n",
      "starting with df:  shows_1997.csv\n",
      "finished with df:  shows_1997.csv\n",
      "starting with df:  shows_2009.csv\n",
      "finished with df:  shows_2009.csv\n",
      "starting with df:  shows_1998.csv\n",
      "finished with df:  shows_1998.csv\n",
      "starting with df:  shows_2010.csv\n",
      "finished with df:  shows_2010.csv\n",
      "starting with df:  shows_1999.csv\n",
      "finished with df:  shows_1999.csv\n",
      "starting with df:  shows_2011.csv\n",
      "finished with df:  shows_2011.csv\n",
      "starting with df:  shows_2000.csv\n",
      "finished with df:  shows_2000.csv\n",
      "starting with df:  shows_2012.csv\n",
      "finished with df:  shows_2012.csv\n",
      "starting with df:  shows_2001.csv\n",
      "finished with df:  shows_2001.csv\n",
      "starting with df:  shows_2013.csv\n",
      "finished with df:  shows_2013.csv\n",
      "starting with df:  shows_2002.csv\n",
      "finished with df:  shows_2002.csv\n",
      "starting with df:  shows_2014.csv\n",
      "finished with df:  shows_2014.csv\n",
      "starting with df:  shows_2003.csv\n",
      "finished with df:  shows_2003.csv\n",
      "starting with df:  shows_2015.csv\n",
      "finished with df:  shows_2015.csv\n",
      "starting with df:  shows_2004.csv\n",
      "finished with df:  shows_2004.csv\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "File shows_2016.csvshows_2005.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2173b5f9082c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m'shows_2004.csv'\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'shows_2016.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m 'shows_2005.csv',             'shows_2017.csv']:\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"starting with df: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_api_from_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File shows_2016.csvshows_2005.csv does not exist"
     ]
    }
   ],
   "source": [
    "## getting api data for the whole dataframe is a little bit rough. trying to do it individually. \n",
    "## maybe add parsing json in here, too\n",
    "\n",
    "for i in [\n",
    "'shows_1995.csv',             'shows_2007.csv',\n",
    "'shows_1996.csv',             'shows_2008.csv',\n",
    "'shows_1997.csv',             'shows_2009.csv',\n",
    "'shows_1998.csv',             'shows_2010.csv',\n",
    "'shows_1999.csv',             'shows_2011.csv',\n",
    "'shows_2000.csv',             'shows_2012.csv',\n",
    "'shows_2001.csv',             'shows_2013.csv',\n",
    "'shows_2002.csv',             'shows_2014.csv',\n",
    "'shows_2003.csv',             'shows_2015.csv',\n",
    "'shows_2004.csv',             'shows_2016.csv'\n",
    "'shows_2005.csv',             'shows_2017.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    print \"starting with df: \", i\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['genre'] = df['json'].apply(parse_genre)\n",
    "    df['release_date'] = df['json'].apply(parse_date)\n",
    "    df['runtime'] = df['json'].apply(parse_runtime)\n",
    "    df['seasons'] = df['json'].apply(parse_seasons)\n",
    "    df.to_csv(i, index=False)\n",
    "    print 'finished with df: ', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with df:  shows_2016.csv\n",
      "finished with df:  shows_2016.csv\n",
      "starting with df:  shows_2005.csv\n",
      "finished with df:  shows_2005.csv\n",
      "starting with df:  shows_2017.csv\n",
      "finished with df:  shows_2017.csv\n"
     ]
    }
   ],
   "source": [
    "for i in ['shows_2016.csv',\n",
    "'shows_2005.csv',             'shows_2017.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    print \"starting with df: \", i\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['genre'] = df['json'].apply(parse_genre)\n",
    "    df['release_date'] = df['json'].apply(parse_date)\n",
    "    df['runtime'] = df['json'].apply(parse_runtime)\n",
    "    df['seasons'] = df['json'].apply(parse_seasons)\n",
    "    df.to_csv(i, index=False)\n",
    "    print 'finished with df: ', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with df:  shows_1995.csv\n",
      "finished with df:  shows_1995.csv\n",
      "starting with df:  shows_2006.csv\n",
      "finished with df:  shows_2006.csv\n"
     ]
    }
   ],
   "source": [
    "# 19955 screwed up, and 2006 didn't make it in for some reason\n",
    "\n",
    "for i in ['shows_1995.csv', 'shows_2006.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    print \"starting with df: \", i\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['genre'] = df['json'].apply(parse_genre)\n",
    "    df['release_date'] = df['json'].apply(parse_date)\n",
    "    df['runtime'] = df['json'].apply(parse_runtime)\n",
    "    df['seasons'] = df['json'].apply(parse_seasons)\n",
    "    df.to_csv(i, index=False)\n",
    "    print 'finished with df: ', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combining years into one dataframe\n",
    "all_shows = pd.read_csv('shows_1995.csv')\n",
    "for i in [\n",
    "            'shows_2007.csv', 'shows_2006.csv',\n",
    "'shows_1996.csv',             'shows_2008.csv',\n",
    "'shows_1997.csv',             'shows_2009.csv',\n",
    "'shows_1998.csv',             'shows_2010.csv',\n",
    "'shows_1999.csv',             'shows_2011.csv',\n",
    "'shows_2000.csv',             'shows_2012.csv',\n",
    "'shows_2001.csv',             'shows_2013.csv',\n",
    "'shows_2002.csv',             'shows_2014.csv',\n",
    "'shows_2003.csv',             'shows_2015.csv',\n",
    "'shows_2004.csv',             'shows_2016.csv',\n",
    "'shows_2005.csv',             'shows_2017.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    all_shows = pd.concat([all_shows, df])\n",
    "    all_shows.to_csv('all_shows.csv', index=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot Experience the magic and adventure from Walt Disney world of color\n",
      "Rated N/A\n",
      "Title The Wonderful World of Disney\n",
      "Ratings [{u'Source': u'Internet Movie Database', u'Value': u'7.0/10'}]\n",
      "Writer Dick Clair, Jenna McMahon\n",
      "Actors David Sparrow, Will Friedle, Laurie Murdoch, Neil Crone\n",
      "Type series\n",
      "imdbVotes 133\n",
      "totalSeasons 39\n",
      "Poster https://images-na.ssl-images-amazon.com/images/M/MV5BYTkzZWE1MDEtNzA1MS00NjY3LTgxMGQtZWQxNDdjMzc5YWQ2XkEyXkFqcGdeQXVyMzM4MjM0Nzg@._V1_SX300.jpg\n",
      "Director N/A\n",
      "Released 28 Sep 1997\n",
      "Awards Won 1 Primetime Emmy. Another 4 nominations.\n",
      "Genre Animation, Action, Adventure\n",
      "Response True\n",
      "Language English\n",
      "Country USA\n",
      "Runtime 120 min\n",
      "imdbID tt0132666\n",
      "Metascore N/A\n",
      "imdbRating 7.0\n",
      "Year 1995–2005\n"
     ]
    }
   ],
   "source": [
    "for i in shows_1995['json'][0]:\n",
    "    print i, shows_1995['json'][0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year =  1995\n",
      "(184, 8)\n",
      "Year =  1996\n",
      "(385, 7)\n",
      "Year =  1997\n",
      "(390, 7)\n",
      "Year =  1998\n",
      "(446, 7)\n",
      "Year =  1999\n",
      "(460, 7)\n",
      "Year =  2000\n",
      "(548, 7)\n",
      "Year =  2001\n",
      "(568, 7)\n",
      "Year =  2002\n",
      "(610, 7)\n",
      "Year =  2003\n",
      "(834, 7)\n",
      "Year =  2004\n",
      "(849, 7)\n",
      "Year =  2005\n",
      "(1076, 7)\n",
      "Year =  2006\n",
      "(1153, 7)\n",
      "Year =  2007\n",
      "(1299, 7)\n",
      "Year =  2008\n",
      "(1442, 7)\n",
      "Year =  2009\n",
      "(1653, 7)\n",
      "Year =  2010\n",
      "(1978, 7)\n",
      "Year =  2011\n",
      "(2500, 7)\n",
      "Year =  2012\n",
      "(2500, 7)\n",
      "Year =  2013\n",
      "(2500, 7)\n",
      "Year =  2014\n",
      "(2500, 7)\n",
      "Year =  2015\n",
      "(2500, 7)\n",
      "Year =  2016\n",
      "(2500, 7)\n",
      "Year =  2017\n",
      "(1691, 7)\n"
     ]
    }
   ],
   "source": [
    "## how many rows/columns made it into each dataframe?\n",
    "for i in range(1995,2018):\n",
    "    print \"Year = \", i\n",
    "    df_name = 'shows_' + str(i) + '.csv'\n",
    "    temp_df = pd.read_csv(df_name)\n",
    "    print temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shows = pd.read_csv('all_shows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30566, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>id</th>\n",
       "      <th>json</th>\n",
       "      <th>plot</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seasons</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30536</th>\n",
       "      <td>action</td>\n",
       "      <td>tt6516766</td>\n",
       "      <td>{u'Plot': u'Hidden from the sight of ordinary ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Project Child: Origins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30537</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt4448530</td>\n",
       "      <td>{u'Plot': u\"HTMARS is a show that reveals the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07 Feb 2015</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1</td>\n",
       "      <td>How to Make a Reality Star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30538</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt6400532</td>\n",
       "      <td>{u'Plot': u'Eye Daily, now scripted, is a come...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Eye Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30539</th>\n",
       "      <td>documentary, music</td>\n",
       "      <td>tt6628886</td>\n",
       "      <td>{u'Plot': u\"Join us at Katsucon 2017 for this ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Cos-Tunes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30540</th>\n",
       "      <td>action, drama</td>\n",
       "      <td>tt5788678</td>\n",
       "      <td>{u'Plot': u'The Rescue is an American action-d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>The Rescue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30541</th>\n",
       "      <td>crime</td>\n",
       "      <td>tt6476428</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Dead Girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30542</th>\n",
       "      <td>documentary</td>\n",
       "      <td>tt7237764</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Weekends with Yankee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30543</th>\n",
       "      <td>comedy, drama</td>\n",
       "      <td>tt4242166</td>\n",
       "      <td>{u'Plot': u'Using their friendship and passion...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Dec 2015</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1</td>\n",
       "      <td>Paying Dues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30544</th>\n",
       "      <td>talk-show</td>\n",
       "      <td>tt6504652</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>ARK: Survival Evolved Xbox One Tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30545</th>\n",
       "      <td>horror</td>\n",
       "      <td>tt6938926</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Don't Turn Around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30546</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt5532058</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>30</td>\n",
       "      <td>n/a</td>\n",
       "      <td>The Unfuckables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30547</th>\n",
       "      <td>crime</td>\n",
       "      <td>tt5874762</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Tráfico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30548</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt6811562</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Jeff Ross Presents Roast Battle II: New York R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30549</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt6689110</td>\n",
       "      <td>{u'Plot': u'This is the story of an unlicensed...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>16</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Shrinkage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30550</th>\n",
       "      <td>reality-tv</td>\n",
       "      <td>tt6495902</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Matti from LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30551</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt5990108</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>How Did He Get Her?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30552</th>\n",
       "      <td>documentary</td>\n",
       "      <td>tt5873362</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>La Femme Vitale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30553</th>\n",
       "      <td>drama</td>\n",
       "      <td>tt6547524</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Every Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30554</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt6849816</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Lo$T BoyZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30555</th>\n",
       "      <td>sci-fi</td>\n",
       "      <td>tt6192884</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Geeks Vs. Aliens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30556</th>\n",
       "      <td>sport</td>\n",
       "      <td>tt7004272</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Gun Stock Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30557</th>\n",
       "      <td>horror</td>\n",
       "      <td>tt6897644</td>\n",
       "      <td>{u'Plot': u'The host of the show Armando Acost...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Demonic Photoshop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30558</th>\n",
       "      <td>sci-fi</td>\n",
       "      <td>tt6949658</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08 Mar 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Future Frank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30559</th>\n",
       "      <td>biography</td>\n",
       "      <td>tt7097712</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Visions of Greatness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30560</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt7039714</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Me Ton Shoushoukko Sto Hollywood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30561</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt7152688</td>\n",
       "      <td>{u'Plot': u'The Comedian, Steven D. Snyder ran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>The Snyder Show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30562</th>\n",
       "      <td>drama</td>\n",
       "      <td>tt6744180</td>\n",
       "      <td>{u'Plot': u'Alex Burnell is a successful busin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Alex's Guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30563</th>\n",
       "      <td>drama</td>\n",
       "      <td>tt6364900</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>7</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Brown Sub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30564</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt7085778</td>\n",
       "      <td>{u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Playground Punks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30565</th>\n",
       "      <td>comedy</td>\n",
       "      <td>tt7272706</td>\n",
       "      <td>{u'Plot': u'A sketch comedy show based around ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jan 2017</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Zack &amp;amp; Justin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    genre         id  \\\n",
       "30536              action  tt6516766   \n",
       "30537              comedy  tt4448530   \n",
       "30538              comedy  tt6400532   \n",
       "30539  documentary, music  tt6628886   \n",
       "30540       action, drama  tt5788678   \n",
       "30541               crime  tt6476428   \n",
       "30542         documentary  tt7237764   \n",
       "30543       comedy, drama  tt4242166   \n",
       "30544           talk-show  tt6504652   \n",
       "30545              horror  tt6938926   \n",
       "30546              comedy  tt5532058   \n",
       "30547               crime  tt5874762   \n",
       "30548              comedy  tt6811562   \n",
       "30549              comedy  tt6689110   \n",
       "30550          reality-tv  tt6495902   \n",
       "30551              comedy  tt5990108   \n",
       "30552         documentary  tt5873362   \n",
       "30553               drama  tt6547524   \n",
       "30554              comedy  tt6849816   \n",
       "30555              sci-fi  tt6192884   \n",
       "30556               sport  tt7004272   \n",
       "30557              horror  tt6897644   \n",
       "30558              sci-fi  tt6949658   \n",
       "30559           biography  tt7097712   \n",
       "30560              comedy  tt7039714   \n",
       "30561              comedy  tt7152688   \n",
       "30562               drama  tt6744180   \n",
       "30563               drama  tt6364900   \n",
       "30564              comedy  tt7085778   \n",
       "30565              comedy  tt7272706   \n",
       "\n",
       "                                                    json plot release_date  \\\n",
       "30536  {u'Plot': u'Hidden from the sight of ordinary ...  NaN  01 Jan 2017   \n",
       "30537  {u'Plot': u\"HTMARS is a show that reveals the ...  NaN  07 Feb 2015   \n",
       "30538  {u'Plot': u'Eye Daily, now scripted, is a come...  NaN  01 Jan 2017   \n",
       "30539  {u'Plot': u\"Join us at Katsucon 2017 for this ...  NaN  01 Jan 2017   \n",
       "30540  {u'Plot': u'The Rescue is an American action-d...  NaN  01 Jan 2017   \n",
       "30541  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30542  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30543  {u'Plot': u'Using their friendship and passion...  NaN  01 Dec 2015   \n",
       "30544  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30545  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30546  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30547  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30548  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30549  {u'Plot': u'This is the story of an unlicensed...  NaN  01 Jan 2017   \n",
       "30550  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30551  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30552  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30553  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30554  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30555  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30556  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30557  {u'Plot': u'The host of the show Armando Acost...  NaN  01 Jan 2017   \n",
       "30558  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  08 Mar 2017   \n",
       "30559  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30560  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30561  {u'Plot': u'The Comedian, Steven D. Snyder ran...  NaN  01 Jan 2017   \n",
       "30562  {u'Plot': u'Alex Burnell is a successful busin...  NaN  01 Jan 2017   \n",
       "30563  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30564  {u'Plot': u'N/A', u'Rated': u'N/A', u'Title': ...  NaN  01 Jan 2017   \n",
       "30565  {u'Plot': u'A sketch comedy show based around ...  NaN  01 Jan 2017   \n",
       "\n",
       "      runtime seasons                                              title  \n",
       "30536     n/a     n/a                             Project Child: Origins  \n",
       "30537     n/a       1                         How to Make a Reality Star  \n",
       "30538       1       2                                          Eye Daily  \n",
       "30539     n/a     n/a                                          Cos-Tunes  \n",
       "30540      60       1                                         The Rescue  \n",
       "30541     n/a     n/a                                          Dead Girl  \n",
       "30542     n/a     n/a                               Weekends with Yankee  \n",
       "30543     n/a       1                                        Paying Dues  \n",
       "30544     n/a     n/a            ARK: Survival Evolved Xbox One Tutorial  \n",
       "30545     n/a     n/a                                  Don't Turn Around  \n",
       "30546      30     n/a                                    The Unfuckables  \n",
       "30547     n/a     n/a                                            Tráfico  \n",
       "30548     n/a     n/a  Jeff Ross Presents Roast Battle II: New York R...  \n",
       "30549      16     n/a                                          Shrinkage  \n",
       "30550     n/a     n/a                                      Matti from LA  \n",
       "30551     n/a     n/a                                How Did He Get Her?  \n",
       "30552     n/a     n/a                                    La Femme Vitale  \n",
       "30553     n/a     n/a                                         Every Time  \n",
       "30554     n/a     n/a                                          Lo$T BoyZ  \n",
       "30555     n/a     n/a                                   Geeks Vs. Aliens  \n",
       "30556     n/a     n/a                                  Gun Stock Reviews  \n",
       "30557     n/a     n/a                                  Demonic Photoshop  \n",
       "30558     n/a     n/a                                       Future Frank  \n",
       "30559     n/a     n/a                               Visions of Greatness  \n",
       "30560     n/a     n/a                   Me Ton Shoushoukko Sto Hollywood  \n",
       "30561     n/a     n/a                                    The Snyder Show  \n",
       "30562     n/a     n/a                                         Alex's Guy  \n",
       "30563       7     n/a                                          Brown Sub  \n",
       "30564     n/a     n/a                                   Playground Punks  \n",
       "30565     n/a     n/a                                  Zack &amp; Justin  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shows.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n/a     15459\n",
       "1        9404\n",
       "2        2479\n",
       "3        1131\n",
       "4         607\n",
       "5         409\n",
       "6         258\n",
       "7         210\n",
       "8         145\n",
       "9         125\n",
       "10         68\n",
       "11         54\n",
       "12         38\n",
       "13         29\n",
       "14         25\n",
       "15         25\n",
       "16         20\n",
       "17         12\n",
       "18          9\n",
       "19          8\n",
       "20          7\n",
       "21          6\n",
       "24          6\n",
       "22          5\n",
       "2013        3\n",
       "27          3\n",
       "23          3\n",
       "25          2\n",
       "39          2\n",
       "26          1\n",
       "106         1\n",
       "130         1\n",
       "29          1\n",
       "31          1\n",
       "30          1\n",
       "37          1\n",
       "34          1\n",
       "42          1\n",
       "2016        1\n",
       "2011        1\n",
       "46          1\n",
       "44          1\n",
       "102         1\n",
       "Name: seasons, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shows['seasons'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows['json'] = shows['id'].apply(get_api_from_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
