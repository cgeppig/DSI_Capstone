{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "from imdbpie import Imdb\n",
    "from time import sleep\n",
    "import time\n",
    "import requests\n",
    "import string\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_df(list_of_shows, year):\n",
    "    temp_df = pd.DataFrame(list_of_shows, columns=['id', 'title'])\n",
    "    df_name = \"shows_\" + str(year) + '.csv'\n",
    "    temp_df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scrapes shows between 2000 and 2015\n",
    "## maybe do it by year\n",
    "## this doesn't work for some reason\n",
    "\n",
    "# all_shows = []\n",
    "# for page in range(1,111):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2000,2015&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     print \"scraping page :\"\n",
    "#     print page,\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 all_shows.append([imdbid,name])\n",
    "#                 sleep(1)\n",
    "#     sleep(1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2015 shows\n",
    "\n",
    "# shows2015 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2015,2015&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2015.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2015, 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2014 shows\n",
    "\n",
    "# shows2014 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2014,2014&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2014.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(5)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2014, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2013 shows\n",
    "\n",
    "# shows2013 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=2013,2013&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2013.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2013, 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2012 shows\n",
    "# years = '2012,2012'\n",
    "# shows2012 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2013.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2012, 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2011 shows\n",
    "# year = '2011'\n",
    "# years = year + ',' + year\n",
    "# shows2011 = []\n",
    "# print \"Scraped Page: \"\n",
    "# for page in range(1,11):\n",
    "#     url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#     soup2000 = BeautifulSoup(url2000)\n",
    "#     for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#         for span in table('span', {'class': 'lister-item-header'}):\n",
    "#             for title in span('a'):\n",
    "#                 imdbid = str(title).split('/')[2]\n",
    "#                 name = str(title).split('>')[1].split('<')[0]\n",
    "#                 shows2013.append([imdbid, name])\n",
    "#                 sleep(1)\n",
    "#     sleep(2)\n",
    "#     print page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list_to_df(shows2011, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(shows2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## scrape all years\n",
    "\n",
    "## I made a better way of doing this\n",
    "\n",
    "# for i in range(1995,2017):\n",
    "#     year = str(i)\n",
    "#     years = year + ',' + year\n",
    "#     shows_temp = []\n",
    "#     print \"Scraping year: \", year\n",
    "#     print \"Scraped Page: \"\n",
    "#     for page in range(1,11):\n",
    "#         url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "#         soup2000 = BeautifulSoup(url2000)\n",
    "#         for table in soup2000('div', {'class': 'lister-list'}):\n",
    "#             for span in table('span', {'class': 'lister-item-header'}):\n",
    "#                 for title in span('a'):\n",
    "#                     imdbid = str(title).split('/')[2]\n",
    "#                     name = str(title).split('>')[1].split('<')[0]\n",
    "#                     shows_temp.append([imdbid, name])\n",
    "#                     sleep(2)\n",
    "#         sleep(5)\n",
    "#         print page,\n",
    "#     temp_df = pd.DataFrame(shows_temp, columns=['id', 'title'])\n",
    "#     df_name = \"shows_\" + year + '.csv'\n",
    "#     temp_df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function for scraping a single year\n",
    "## scrapes 2500 shows for the given year\n",
    "## exports as dataframe with name 'shows_[year].csv'\n",
    "\n",
    "def scrape_year(year):\n",
    "    year = str(year)\n",
    "    years = year + ',' + year\n",
    "    shows_temp = []\n",
    "    print \"Scraping Year: \", year\n",
    "    print \"Scraped Pages: \"\n",
    "    for page in range(1,11):\n",
    "        url2000 = urllib2.urlopen('http://www.imdb.com/search/title?count=250&countries=us&languages=en&production_status=released&release_date=' + years + '&title_type=tv_series&view=simple&sort=release_date,desc&page=' + str(page) + '&ref_=adv_nxt')\n",
    "        soup2000 = BeautifulSoup(url2000)\n",
    "        for table in soup2000('div', {'class': 'lister-list'}):\n",
    "            for span in table('span', {'class': 'lister-item-header'}):\n",
    "                for title in span('a'):\n",
    "                    imdbid = str(title).split('/')[2]\n",
    "                    name = str(title).split('>')[1].split('<')[0]\n",
    "                    shows_temp.append([imdbid, name])\n",
    "        print page,\n",
    "        sleep(5)\n",
    "    temp_df = pd.DataFrame(shows_temp, columns=['id', 'title'])\n",
    "    print \"\\n\", temp_df.shape[0], \" Shows Scraped\"\n",
    "    df_name = \"shows_\" + year + '.csv'\n",
    "    temp_df.to_csv(df_name, index=False)\n",
    "    print \"csv file created for: \", year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I don't know for sure whether the earlier years have 2500 shows each (it looks like they don't)\n",
    "\n",
    "\n",
    "for i in range(1995,2000):\n",
    "    scrape_year(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000,2018):\n",
    "    scrape_year(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_shows.to_csv('all_shows.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleach(string):\n",
    "    temp = \"\"\n",
    "    string = str(string)\n",
    "    for i in string:\n",
    "        if i in [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\".\"]:\n",
    "            temp += i\n",
    "    if len(temp) > 0:\n",
    "        return float(temp)\n",
    "\n",
    "def combine_list(list):\n",
    "    temp = \"\"\n",
    "    for i in list:\n",
    "        temp += \" \" + i\n",
    "    return temp\n",
    "\n",
    "def get_api_from_id(title_id):\n",
    "    try: \n",
    "        this_url = \"http://www.omdbapi.com/?i=\" + title_id + \"&plot=full&r=json&apikey=9f5296af\"\n",
    "        req = requests.get(this_url)\n",
    "        return req.json()\n",
    "    except:\n",
    "        return \"something is wrong\"\n",
    "\n",
    "def data_from_api(df):\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['name'] = df['json'].apply(lambda x: x['Title'])\n",
    "    df['genres'] = df['json'].apply(lambda x: str.lower(str(x['Genre'])))\n",
    "    df['seasons'] = df['json'].apply(lambda x: bleach(x['totalSeasons']))\n",
    "    df['runtime'] = df['json'].apply(lambda x: bleach(x['Runtime']))\n",
    "    df['release_date'] = df['json'].apply(lambda x: x['Released'])\n",
    "\n",
    "def parse_json(df):\n",
    "    df['json_title'] = df['json'].apply(lambda x: x['Title'])\n",
    "    df['genres'] = df['json'].apply(lambda x: str.lower(str(x['Genre'])))\n",
    "    df['seasons'] = df['json'].apply(lambda x: bleach(x['totalSeasons']))\n",
    "    df['runtime'] = df['json'].apply(lambda x: bleach(x['Runtime']))\n",
    "    df['release_date'] = df['json'].apply(lambda x: x['Released'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_genre(json):\n",
    "    try:\n",
    "        return str.lower(str(json['Genre']))\n",
    "    except:\n",
    "        return \"n/a\"\n",
    "\n",
    "def parse_date(json):\n",
    "    try:\n",
    "        return str(json['Released'])\n",
    "    except:\n",
    "        return \"n/a\"\n",
    "    \n",
    "def parse_runtime(json):\n",
    "    try:\n",
    "        return int(bleach(str(json['Runtime'])))\n",
    "    except:\n",
    "        return \"n/a\"\n",
    "\n",
    "def parse_seasons(json):\n",
    "    try:\n",
    "        return int(json['totalSeasons'])\n",
    "    except:\n",
    "        return \"n/a\"\n",
    "    \n",
    "def parse_plot(json):\n",
    "    try:\n",
    "        return json['Plot']\n",
    "    except:\n",
    "        return \"n/a\"\n",
    "    \n",
    "    \n",
    "    \n",
    "def scrape_network(id):\n",
    "    words = \"\"\n",
    "    url = \"http://www.imdb.com/title/\" + id + \"/companycredits?ref_=ttspec_sa_5\"\n",
    "    soup = BeautifulSoup(urllib2.urlopen(url), \"html5lib\")\n",
    "    simpleLists = soup.find_all('ul', {'class': 'simpleList'})\n",
    "    try:\n",
    "        for li in simpleLists[1]('li'):\n",
    "            for a in li('a'):\n",
    "                words += (a.get_text() + '\\n')\n",
    "        return words.split(\"\\n\")[0]\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "    sleep(2)\n",
    "\n",
    "\n",
    "def access_keyword_page(imdbID):\n",
    "    return 'http://www.imdb.com/title/' + imdbID + '/keywords?ref_=tt_stry_kw'\n",
    "\n",
    "def scrape_keywords(imdbID):\n",
    "    soup_for_keywords = BeautifulSoup(urllib2.urlopen(access_keyword_page(imdbID)), \"html5lib\")\n",
    "    temp_keywords = []\n",
    "    for div in soup_for_keywords('div', {'id':'keywords_content'}):\n",
    "        for text in div('div', {'class':'sodatext'}):\n",
    "            for a in text('a'):\n",
    "                temp_keywords.append(a.get_text())\n",
    "    return temp_keywords\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_json(json):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with df:  shows_1995.csv\n",
      "finished with df:  shows_1995.csv\n"
     ]
    }
   ],
   "source": [
    "## testing\n",
    "## it seems to work well\n",
    "\n",
    "for i in [\n",
    "'shows_1995.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    print \"starting with df: \", i\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['genre'] = df['json'].apply(parse_genre)\n",
    "    df['release_date'] = df['json'].apply(parse_date)\n",
    "    df['runtime'] = df['json'].apply(parse_runtime)\n",
    "    df['seasons'] = df['json'].apply(parse_seasons)\n",
    "    df.to_csv(i, index=False)\n",
    "    print 'finished with df: ', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with df:  shows_1995.csv\n",
      "finished with df:  shows_1995.csv\n",
      "starting with df:  shows_2007.csv\n",
      "finished with df:  shows_2007.csv\n",
      "starting with df:  shows_1996.csv\n",
      "finished with df:  shows_1996.csv\n",
      "starting with df:  shows_2008.csv\n",
      "finished with df:  shows_2008.csv\n",
      "starting with df:  shows_1997.csv\n",
      "finished with df:  shows_1997.csv\n",
      "starting with df:  shows_2009.csv\n",
      "finished with df:  shows_2009.csv\n",
      "starting with df:  shows_1998.csv\n",
      "finished with df:  shows_1998.csv\n",
      "starting with df:  shows_2010.csv\n",
      "finished with df:  shows_2010.csv\n",
      "starting with df:  shows_1999.csv\n",
      "finished with df:  shows_1999.csv\n",
      "starting with df:  shows_2011.csv\n",
      "finished with df:  shows_2011.csv\n",
      "starting with df:  shows_2000.csv\n",
      "finished with df:  shows_2000.csv\n",
      "starting with df:  shows_2012.csv\n",
      "finished with df:  shows_2012.csv\n",
      "starting with df:  shows_2001.csv\n",
      "finished with df:  shows_2001.csv\n",
      "starting with df:  shows_2013.csv\n",
      "finished with df:  shows_2013.csv\n",
      "starting with df:  shows_2002.csv\n",
      "finished with df:  shows_2002.csv\n",
      "starting with df:  shows_2014.csv\n",
      "finished with df:  shows_2014.csv\n",
      "starting with df:  shows_2003.csv\n",
      "finished with df:  shows_2003.csv\n",
      "starting with df:  shows_2015.csv\n",
      "finished with df:  shows_2015.csv\n",
      "starting with df:  shows_2004.csv\n",
      "finished with df:  shows_2004.csv\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "File shows_2016.csvshows_2005.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2173b5f9082c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m'shows_2004.csv'\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'shows_2016.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m 'shows_2005.csv',             'shows_2017.csv']:\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"starting with df: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'json'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_api_from_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File shows_2016.csvshows_2005.csv does not exist"
     ]
    }
   ],
   "source": [
    "## getting api data for the whole dataframe is a little bit rough. trying to do it individually. \n",
    "## maybe add parsing json in here, too\n",
    "\n",
    "for i in [\n",
    "'shows_1995.csv',             'shows_2007.csv',\n",
    "'shows_1996.csv',             'shows_2008.csv',\n",
    "'shows_1997.csv',             'shows_2009.csv',\n",
    "'shows_1998.csv',             'shows_2010.csv',\n",
    "'shows_1999.csv',             'shows_2011.csv',\n",
    "'shows_2000.csv',             'shows_2012.csv',\n",
    "'shows_2001.csv',             'shows_2013.csv',\n",
    "'shows_2002.csv',             'shows_2014.csv',\n",
    "'shows_2003.csv',             'shows_2015.csv',\n",
    "'shows_2004.csv',             'shows_2016.csv'\n",
    "'shows_2005.csv',             'shows_2017.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    print \"starting with df: \", i\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['genre'] = df['json'].apply(parse_genre)\n",
    "    df['release_date'] = df['json'].apply(parse_date)\n",
    "    df['runtime'] = df['json'].apply(parse_runtime)\n",
    "    df['seasons'] = df['json'].apply(parse_seasons)\n",
    "    df.to_csv(i, index=False)\n",
    "    print 'finished with df: ', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with df:  shows_2016.csv\n",
      "finished with df:  shows_2016.csv\n",
      "starting with df:  shows_2005.csv\n",
      "finished with df:  shows_2005.csv\n",
      "starting with df:  shows_2017.csv\n",
      "finished with df:  shows_2017.csv\n"
     ]
    }
   ],
   "source": [
    "for i in ['shows_2016.csv',\n",
    "'shows_2005.csv',             'shows_2017.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    print \"starting with df: \", i\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['genre'] = df['json'].apply(parse_genre)\n",
    "    df['release_date'] = df['json'].apply(parse_date)\n",
    "    df['runtime'] = df['json'].apply(parse_runtime)\n",
    "    df['seasons'] = df['json'].apply(parse_seasons)\n",
    "    df.to_csv(i, index=False)\n",
    "    print 'finished with df: ', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with df:  shows_1995.csv\n",
      "finished with df:  shows_1995.csv\n",
      "starting with df:  shows_2006.csv\n",
      "finished with df:  shows_2006.csv\n"
     ]
    }
   ],
   "source": [
    "# 1995 screwed up, and 2006 didn't make it in for some reason\n",
    "\n",
    "for i in ['shows_1995.csv', 'shows_2006.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    print \"starting with df: \", i\n",
    "    df['json'] = df['id'].apply(get_api_from_id)\n",
    "    df['genre'] = df['json'].apply(parse_genre)\n",
    "    df['release_date'] = df['json'].apply(parse_date)\n",
    "    df['runtime'] = df['json'].apply(parse_runtime)\n",
    "    df['seasons'] = df['json'].apply(parse_seasons)\n",
    "    df.to_csv(i, index=False)\n",
    "    print 'finished with df: ', i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combining years into one dataframe\n",
    "all_shows = pd.read_csv('shows_1995.csv')\n",
    "for i in [\n",
    "            'shows_2007.csv', 'shows_2006.csv',\n",
    "'shows_1996.csv',             'shows_2008.csv',\n",
    "'shows_1997.csv',             'shows_2009.csv',\n",
    "'shows_1998.csv',             'shows_2010.csv',\n",
    "'shows_1999.csv',             'shows_2011.csv',\n",
    "'shows_2000.csv',             'shows_2012.csv',\n",
    "'shows_2001.csv',             'shows_2013.csv',\n",
    "'shows_2002.csv',             'shows_2014.csv',\n",
    "'shows_2003.csv',             'shows_2015.csv',\n",
    "'shows_2004.csv',             'shows_2016.csv',\n",
    "'shows_2005.csv',             'shows_2017.csv']:\n",
    "    df = pd.read_csv(i)\n",
    "    all_shows = pd.concat([all_shows, df])\n",
    "    all_shows.to_csv('all_shows.csv', index=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot Experience the magic and adventure from Walt Disney world of color\n",
      "Rated N/A\n",
      "Title The Wonderful World of Disney\n",
      "Ratings [{u'Source': u'Internet Movie Database', u'Value': u'7.0/10'}]\n",
      "Writer Dick Clair, Jenna McMahon\n",
      "Actors David Sparrow, Will Friedle, Laurie Murdoch, Neil Crone\n",
      "Type series\n",
      "imdbVotes 133\n",
      "totalSeasons 39\n",
      "Poster https://images-na.ssl-images-amazon.com/images/M/MV5BYTkzZWE1MDEtNzA1MS00NjY3LTgxMGQtZWQxNDdjMzc5YWQ2XkEyXkFqcGdeQXVyMzM4MjM0Nzg@._V1_SX300.jpg\n",
      "Director N/A\n",
      "Released 28 Sep 1997\n",
      "Awards Won 1 Primetime Emmy. Another 4 nominations.\n",
      "Genre Animation, Action, Adventure\n",
      "Response True\n",
      "Language English\n",
      "Country USA\n",
      "Runtime 120 min\n",
      "imdbID tt0132666\n",
      "Metascore N/A\n",
      "imdbRating 7.0\n",
      "Year 1995–2005\n"
     ]
    }
   ],
   "source": [
    "for i in shows_1995['json'][0]:\n",
    "    print i, shows_1995['json'][0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year =  1995\n",
      "(184, 8)\n",
      "Year =  1996\n",
      "(385, 7)\n",
      "Year =  1997\n",
      "(390, 7)\n",
      "Year =  1998\n",
      "(446, 7)\n",
      "Year =  1999\n",
      "(460, 7)\n",
      "Year =  2000\n",
      "(548, 7)\n",
      "Year =  2001\n",
      "(568, 7)\n",
      "Year =  2002\n",
      "(610, 7)\n",
      "Year =  2003\n",
      "(834, 7)\n",
      "Year =  2004\n",
      "(849, 7)\n",
      "Year =  2005\n",
      "(1076, 7)\n",
      "Year =  2006\n",
      "(1153, 7)\n",
      "Year =  2007\n",
      "(1299, 7)\n",
      "Year =  2008\n",
      "(1442, 7)\n",
      "Year =  2009\n",
      "(1653, 7)\n",
      "Year =  2010\n",
      "(1978, 7)\n",
      "Year =  2011\n",
      "(2500, 7)\n",
      "Year =  2012\n",
      "(2500, 7)\n",
      "Year =  2013\n",
      "(2500, 7)\n",
      "Year =  2014\n",
      "(2500, 7)\n",
      "Year =  2015\n",
      "(2500, 7)\n",
      "Year =  2016\n",
      "(2500, 7)\n",
      "Year =  2017\n",
      "(1691, 7)\n"
     ]
    }
   ],
   "source": [
    "## how many rows/columns made it into each dataframe?\n",
    "for i in range(1995,2018):\n",
    "    print \"Year = \", i\n",
    "    df_name = 'shows_' + str(i) + '.csv'\n",
    "    temp_df = pd.read_csv(df_name)\n",
    "    print temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shows = pd.read_csv('all_shows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30566, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## drops ~15000 rows\n",
    "clean_shows = shows[shows['seasons']!='n/a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15107, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_shows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## drop another ~2000 rows with no release date\n",
    "clean_shows_2 = clean_shows[clean_shows['release_date'].isnull()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13274, 8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_shows_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n/a    7249\n",
       "30     1915\n",
       "60     1419\n",
       "22      396\n",
       "5       191\n",
       "Name: runtime, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## about half of the shows are missing runtime data\n",
    "clean_shows_2['runtime'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184     1\n",
       "185     1\n",
       "3900    1\n",
       "325     1\n",
       "200     1\n",
       "73      1\n",
       "70      1\n",
       "78      1\n",
       "123     1\n",
       "270     1\n",
       "Name: runtime, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## looks like there are a few with weird runtimes, too\n",
    "clean_shows_2['runtime'].value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre           object\n",
       "id              object\n",
       "json            object\n",
       "plot            object\n",
       "release_date    object\n",
       "runtime         object\n",
       "seasons         object\n",
       "title           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_shows_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophereppig/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "clean_shows_2['clean_runtime'] = clean_shows_2['runtime'].apply(lambda x: int(x) if x!='n/a' else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>id</th>\n",
       "      <th>json</th>\n",
       "      <th>plot</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seasons</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animation, action, adventure</td>\n",
       "      <td>tt0132666</td>\n",
       "      <td>{u'Plot': u'Experience the magic and adventure...</td>\n",
       "      <td>Experience the magic and adventure from Walt D...</td>\n",
       "      <td>28 Sep 1997</td>\n",
       "      <td>120</td>\n",
       "      <td>39</td>\n",
       "      <td>The Wonderful World of Disney</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>animation, comedy, family</td>\n",
       "      <td>tt0118289</td>\n",
       "      <td>{u'Plot': u'The program focuses on the misadve...</td>\n",
       "      <td>The program focuses on the misadventures of tw...</td>\n",
       "      <td>15 Jul 1997</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>Cow and Chicken</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action, animation, sci-fi</td>\n",
       "      <td>tt0122355</td>\n",
       "      <td>{u'Plot': u'Fighters from Mortal Kombat tourna...</td>\n",
       "      <td>Fighters from Mortal Kombat tournaments from o...</td>\n",
       "      <td>21 Sep 1996</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Mortal Kombat: Defenders of the Realm</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n/a</td>\n",
       "      <td>tt0222529</td>\n",
       "      <td>{u'Plot': u'Miles Peterson, a regular guy with...</td>\n",
       "      <td>Miles Peterson, a regular guy with the best th...</td>\n",
       "      <td>06 May 2004</td>\n",
       "      <td>n/a</td>\n",
       "      <td>5</td>\n",
       "      <td>Bibleman</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>animation, comedy, musical</td>\n",
       "      <td>tt0111911</td>\n",
       "      <td>{u'Plot': u'Following success as a late night ...</td>\n",
       "      <td>Following success as a late night talk show ho...</td>\n",
       "      <td>10 Sep 1997</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartoon Planet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           genre         id  \\\n",
       "0   animation, action, adventure  tt0132666   \n",
       "1      animation, comedy, family  tt0118289   \n",
       "2      action, animation, sci-fi  tt0122355   \n",
       "3                            n/a  tt0222529   \n",
       "13    animation, comedy, musical  tt0111911   \n",
       "\n",
       "                                                 json  \\\n",
       "0   {u'Plot': u'Experience the magic and adventure...   \n",
       "1   {u'Plot': u'The program focuses on the misadve...   \n",
       "2   {u'Plot': u'Fighters from Mortal Kombat tourna...   \n",
       "3   {u'Plot': u'Miles Peterson, a regular guy with...   \n",
       "13  {u'Plot': u'Following success as a late night ...   \n",
       "\n",
       "                                                 plot release_date runtime  \\\n",
       "0   Experience the magic and adventure from Walt D...  28 Sep 1997     120   \n",
       "1   The program focuses on the misadventures of tw...  15 Jul 1997      30   \n",
       "2   Fighters from Mortal Kombat tournaments from o...  21 Sep 1996      30   \n",
       "3   Miles Peterson, a regular guy with the best th...  06 May 2004     n/a   \n",
       "13  Following success as a late night talk show ho...  10 Sep 1997     n/a   \n",
       "\n",
       "   seasons                                  title  clean_runtime  \n",
       "0       39          The Wonderful World of Disney          120.0  \n",
       "1        4                        Cow and Chicken           30.0  \n",
       "2        1  Mortal Kombat: Defenders of the Realm           30.0  \n",
       "3        5                               Bibleman            NaN  \n",
       "13       1                         Cartoon Planet            NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_shows_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophereppig/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "clean_shows_2['year'] = clean_shows_2['release_date'].apply(lambda x: int(x[-4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>id</th>\n",
       "      <th>json</th>\n",
       "      <th>plot</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>seasons</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_runtime</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animation, action, adventure</td>\n",
       "      <td>tt0132666</td>\n",
       "      <td>{u'Plot': u'Experience the magic and adventure...</td>\n",
       "      <td>Experience the magic and adventure from Walt D...</td>\n",
       "      <td>28 Sep 1997</td>\n",
       "      <td>120</td>\n",
       "      <td>39</td>\n",
       "      <td>The Wonderful World of Disney</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>animation, comedy, family</td>\n",
       "      <td>tt0118289</td>\n",
       "      <td>{u'Plot': u'The program focuses on the misadve...</td>\n",
       "      <td>The program focuses on the misadventures of tw...</td>\n",
       "      <td>15 Jul 1997</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>Cow and Chicken</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action, animation, sci-fi</td>\n",
       "      <td>tt0122355</td>\n",
       "      <td>{u'Plot': u'Fighters from Mortal Kombat tourna...</td>\n",
       "      <td>Fighters from Mortal Kombat tournaments from o...</td>\n",
       "      <td>21 Sep 1996</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Mortal Kombat: Defenders of the Realm</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n/a</td>\n",
       "      <td>tt0222529</td>\n",
       "      <td>{u'Plot': u'Miles Peterson, a regular guy with...</td>\n",
       "      <td>Miles Peterson, a regular guy with the best th...</td>\n",
       "      <td>06 May 2004</td>\n",
       "      <td>n/a</td>\n",
       "      <td>5</td>\n",
       "      <td>Bibleman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>animation, comedy, musical</td>\n",
       "      <td>tt0111911</td>\n",
       "      <td>{u'Plot': u'Following success as a late night ...</td>\n",
       "      <td>Following success as a late night talk show ho...</td>\n",
       "      <td>10 Sep 1997</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartoon Planet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           genre         id  \\\n",
       "0   animation, action, adventure  tt0132666   \n",
       "1      animation, comedy, family  tt0118289   \n",
       "2      action, animation, sci-fi  tt0122355   \n",
       "3                            n/a  tt0222529   \n",
       "13    animation, comedy, musical  tt0111911   \n",
       "\n",
       "                                                 json  \\\n",
       "0   {u'Plot': u'Experience the magic and adventure...   \n",
       "1   {u'Plot': u'The program focuses on the misadve...   \n",
       "2   {u'Plot': u'Fighters from Mortal Kombat tourna...   \n",
       "3   {u'Plot': u'Miles Peterson, a regular guy with...   \n",
       "13  {u'Plot': u'Following success as a late night ...   \n",
       "\n",
       "                                                 plot release_date runtime  \\\n",
       "0   Experience the magic and adventure from Walt D...  28 Sep 1997     120   \n",
       "1   The program focuses on the misadventures of tw...  15 Jul 1997      30   \n",
       "2   Fighters from Mortal Kombat tournaments from o...  21 Sep 1996      30   \n",
       "3   Miles Peterson, a regular guy with the best th...  06 May 2004     n/a   \n",
       "13  Following success as a late night talk show ho...  10 Sep 1997     n/a   \n",
       "\n",
       "   seasons                                  title  clean_runtime  year  \n",
       "0       39          The Wonderful World of Disney          120.0  1997  \n",
       "1        4                        Cow and Chicken           30.0  1997  \n",
       "2        1  Mortal Kombat: Defenders of the Realm           30.0  1996  \n",
       "3        5                               Bibleman            NaN  2004  \n",
       "13       1                         Cartoon Planet            NaN  1997  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_shows_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre             object\n",
       "id                object\n",
       "json              object\n",
       "plot              object\n",
       "release_date      object\n",
       "runtime           object\n",
       "seasons           object\n",
       "title             object\n",
       "clean_runtime    float64\n",
       "year               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_shows_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_shows_2['year'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011    1340\n",
       "2014    1290\n",
       "2012    1289\n",
       "2013    1233\n",
       "2015    1181\n",
       "2010    1085\n",
       "2009     935\n",
       "2016     777\n",
       "2008     710\n",
       "2007     566\n",
       "2006     502\n",
       "2005     422\n",
       "2004     292\n",
       "2003     270\n",
       "2017     206\n",
       "2002     205\n",
       "2001     201\n",
       "2000     171\n",
       "1999     154\n",
       "1998     143\n",
       "1997     133\n",
       "1996     129\n",
       "1995      39\n",
       "2020       1\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_shows_2['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shows_2017_holdout = clean_shows_2[clean_shows_2['year']==2017].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206, 10)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shows_2017_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shows_2017_holdout.to_csv('shows_2017_holdout.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.68000000e+02,   1.33000000e+02,   1.43000000e+02,\n",
       "          1.54000000e+02,   1.71000000e+02,   2.01000000e+02,\n",
       "          2.05000000e+02,   5.62000000e+02,   4.22000000e+02,\n",
       "          5.02000000e+02,   5.66000000e+02,   7.10000000e+02,\n",
       "          9.35000000e+02,   1.08500000e+03,   2.62900000e+03,\n",
       "          1.23300000e+03,   1.29000000e+03,   1.18100000e+03,\n",
       "          7.77000000e+02,   2.06000000e+02,   0.00000000e+00,\n",
       "          1.00000000e+00]),\n",
       " array([ 1995.        ,  1996.13636364,  1997.27272727,  1998.40909091,\n",
       "         1999.54545455,  2000.68181818,  2001.81818182,  2002.95454545,\n",
       "         2004.09090909,  2005.22727273,  2006.36363636,  2007.5       ,\n",
       "         2008.63636364,  2009.77272727,  2010.90909091,  2012.04545455,\n",
       "         2013.18181818,  2014.31818182,  2015.45454545,  2016.59090909,\n",
       "         2017.72727273,  2018.86363636,  2020.        ]),\n",
       " <a list of 22 Patch objects>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAFdCAYAAAC0B5/iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCUOFJElqwlAhSZKa+P//OzpJpa+oGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118040e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(clean_shows_2['year'], bins=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-7b2aa101cde4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## separate into 2017, 2016, and the rest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_shows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_shows_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean_shows_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1995\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2016\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/christophereppig/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    915\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m    916\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "## separate into 2017, 2016, and the rest\n",
    "test_shows = clean_shows_2[clean_shows_2['year'] in range(1995,2016)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 9)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## only 138 with strange runtimes. I can drop them.\n",
    "## leaving them in probably wouldn't be a problem, but maybe better to drop them\n",
    "clean_shows_2[clean_shows_2['clean_runtime']>90].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this will take over 8 hours to scrap\n",
    "clean_shows_2['keywords'] = clean_shows_2['id'].apply(scrape_keywords)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
